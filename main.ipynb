{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T10:40:52.682341Z",
     "start_time": "2025-01-11T10:40:44.407704Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data_path = 'Dev_data_to_be_shared.csv'  # Replace with your file path\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Explore the dataset\n",
    "# print(\"Dataset Overview:\")\n",
    "# print(data.head())\n",
    "# print(\"\\nData Info:\")\n",
    "# print(data.info())\n",
    "# print(\"\\nMissing Values:\")\n",
    "# print(data.isnull().sum())\n",
    "# \n",
    "# # Handle missing values (if any)\n",
    "# data.fillna(data.median(numeric_only=True), inplace=True)\n",
    "# \n",
    "# # Separate features and target variable (bad_flag)\n",
    "# X = data.drop(columns=['bad_flag'])\n",
    "# y = data['bad_flag']\n",
    "# \n",
    "# # Convert categorical variables into dummy/indicator variables (if applicable)\n",
    "# X = pd.get_dummies(X, drop_first=True)\n",
    "# \n",
    "# # Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# \n",
    "# # Initialize the model\n",
    "# model = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)\n",
    "# \n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train)\n",
    "# \n",
    "# # Make predictions\n",
    "# y_pred = model.predict(X_test)\n",
    "# \n",
    "# # Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"\\nAccuracy:\", accuracy)\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# \n",
    "# # Feature Importance (Optional)\n",
    "# feature_importance = pd.DataFrame({\n",
    "#     'Feature': X.columns,\n",
    "#     'Importance': model.feature_importances_\n",
    "# }).sort_values(by='Importance', ascending=False)\n",
    "# \n",
    "# print(\"\\nFeature Importances:\")\n",
    "# print(feature_importance)\n",
    "# \n",
    "# # Save the trained model (Optional)\n",
    "# import joblib\n",
    "# joblib.dump(model, 'bad_flag_model.pkl')\n",
    "# \n",
    "# print(\"Model training and evaluation complete.\")\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:40:57.812195Z",
     "start_time": "2025-01-11T10:40:57.551603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Dataset Overview:\")\n",
    "print(data.head())\n",
    "print(\"\\nData Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())"
   ],
   "id": "3ec121e8e1740af3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "   account_number  bad_flag  onus_attribute_1  transaction_attribute_1  \\\n",
      "0               1         0               NaN                      NaN   \n",
      "1               2         0          221000.0                      0.0   \n",
      "2               3         0           25000.0                      0.0   \n",
      "3               4         0           86000.0                      0.0   \n",
      "4               5         0          215000.0                      0.0   \n",
      "\n",
      "   transaction_attribute_2  transaction_attribute_3  transaction_attribute_4  \\\n",
      "0                      NaN                      NaN                      NaN   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   transaction_attribute_5  transaction_attribute_6  transaction_attribute_7  \\\n",
      "0                      NaN                      NaN                      NaN   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   ...  bureau_enquiry_47  bureau_enquiry_48  bureau_enquiry_49  \\\n",
      "0  ...                0.0                0.0                0.0   \n",
      "1  ...                0.0                0.0                2.0   \n",
      "2  ...                0.0                0.0                0.0   \n",
      "3  ...                0.0                0.0                0.0   \n",
      "4  ...                0.0                0.0                0.0   \n",
      "\n",
      "   bureau_enquiry_50  onus_attribute_43  onus_attribute_44  onus_attribute_45  \\\n",
      "0                1.0                NaN                NaN                NaN   \n",
      "1                3.0                0.0                0.0                0.0   \n",
      "2                8.0                NaN                NaN                NaN   \n",
      "3               30.0                NaN                NaN                NaN   \n",
      "4                1.0                NaN                NaN                NaN   \n",
      "\n",
      "   onus_attribute_46  onus_attribute_47  onus_attribute_48  \n",
      "0                NaN                NaN                NaN  \n",
      "1                0.0                0.0                0.0  \n",
      "2                NaN                NaN                NaN  \n",
      "3                NaN                NaN                NaN  \n",
      "4                NaN                NaN                NaN  \n",
      "\n",
      "[5 rows x 1216 columns]\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96806 entries, 0 to 96805\n",
      "Columns: 1216 entries, account_number to onus_attribute_48\n",
      "dtypes: float64(1189), int64(27)\n",
      "memory usage: 898.1 MB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "account_number                 0\n",
      "bad_flag                       0\n",
      "onus_attribute_1           25231\n",
      "transaction_attribute_1    25231\n",
      "transaction_attribute_2    25231\n",
      "                           ...  \n",
      "onus_attribute_44          85196\n",
      "onus_attribute_45          85196\n",
      "onus_attribute_46          85196\n",
      "onus_attribute_47          85196\n",
      "onus_attribute_48          85196\n",
      "Length: 1216, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:54:52.341050Z",
     "start_time": "2025-01-11T10:54:52.319860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count the values of bad_flag\n",
    "print(\"\\nCount of bad_flag values:\")\n",
    "print(data['bad_flag'].value_counts())"
   ],
   "id": "c1a75c4b3d2a52bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of bad_flag values:\n",
      "bad_flag\n",
      "0    95434\n",
      "1     1372\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:43:27.945348Z",
     "start_time": "2025-01-11T10:43:27.509430Z"
    }
   },
   "cell_type": "code",
   "source": "print(data.isnull().sum())\n",
   "id": "b3d9bb4cff42c3a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account_number             0\n",
      "bad_flag                   0\n",
      "onus_attribute_1           0\n",
      "transaction_attribute_1    0\n",
      "transaction_attribute_2    0\n",
      "                          ..\n",
      "onus_attribute_44          0\n",
      "onus_attribute_45          0\n",
      "onus_attribute_46          0\n",
      "onus_attribute_47          0\n",
      "onus_attribute_48          0\n",
      "Length: 1216, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:46:24.404717Z",
     "start_time": "2025-01-11T10:46:19.226911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data.fillna(data.median(numeric_only=True), inplace=True)\n",
    "data.fillna('Unknown', inplace=True)  # For categorical columns\n",
    "# Separate features and target variable (bad_flag)\n",
    "X = data.drop(columns=['bad_flag'])\n",
    "y = data['bad_flag']\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables (if applicable)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ],
   "id": "6ad0134f1ebd9c37",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:46:59.238349Z",
     "start_time": "2025-01-11T10:46:24.414038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the model\n",
    "model = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "83e9f2ccaf50ef47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.98578600499969\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     47715\n",
      "           1       0.00      0.00      0.00       688\n",
      "\n",
      "    accuracy                           0.99     48403\n",
      "   macro avg       0.49      0.50      0.50     48403\n",
      "weighted avg       0.97      0.99      0.98     48403\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tejas Tyagi\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tejas Tyagi\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tejas Tyagi\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:45:53.247250Z",
     "start_time": "2025-01-11T10:45:53.161007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature Importance (Optional)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Save the trained model (Optional)\n",
    "import joblib\n",
    "joblib.dump(model, 'bad_flag_model.pkl')\n",
    "\n",
    "print(\"Model training and evaluation complete.\")\n"
   ],
   "id": "9c08d0a2360a7e73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importances:\n",
      "                        Feature  Importance\n",
      "1116           onus_attribute_2    0.012664\n",
      "1134          onus_attribute_20    0.009366\n",
      "1131          onus_attribute_17    0.009190\n",
      "810                  bureau_145    0.007738\n",
      "1103                 bureau_439    0.007274\n",
      "...                         ...         ...\n",
      "198   transaction_attribute_197    0.000000\n",
      "344   transaction_attribute_343    0.000000\n",
      "197   transaction_attribute_196    0.000000\n",
      "240   transaction_attribute_239    0.000000\n",
      "314   transaction_attribute_313    0.000000\n",
      "\n",
      "[1213 rows x 2 columns]\n",
      "Model training and evaluation complete.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T11:07:51.060928Z",
     "start_time": "2025-01-11T11:07:41.439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Load the development dataset\n",
    "data_path = 'Dev_data_to_be_shared.csv'  # Replace with your file path\n",
    "data = pd.read_csv(data_path)\n"
   ],
   "id": "ead44ef95c36f33e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T11:08:04.884509Z",
     "start_time": "2025-01-11T11:08:04.813868Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d99ea74c79ce9b99",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       account_number  bad_flag  onus_attribute_1  transaction_attribute_1  \\\n",
       "0                   1         0               NaN                      NaN   \n",
       "1                   2         0          221000.0                      0.0   \n",
       "2                   3         0           25000.0                      0.0   \n",
       "3                   4         0           86000.0                      0.0   \n",
       "4                   5         0          215000.0                      0.0   \n",
       "...               ...       ...               ...                      ...   \n",
       "96801           96802         0          156000.0                      0.0   \n",
       "96802           96803         0           46000.0                      0.0   \n",
       "96803           96804         0           95000.0                      0.0   \n",
       "96804           96805         0           88000.0                      0.0   \n",
       "96805           96806         0           94000.0                      0.0   \n",
       "\n",
       "       transaction_attribute_2  transaction_attribute_3  \\\n",
       "0                          NaN                      NaN   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "96801                      0.0                      0.0   \n",
       "96802                      0.0                      0.0   \n",
       "96803                      0.0                      0.0   \n",
       "96804                      0.0                      0.0   \n",
       "96805                      0.0                      0.0   \n",
       "\n",
       "       transaction_attribute_4  transaction_attribute_5  \\\n",
       "0                          NaN                      NaN   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "96801                      0.0                      0.0   \n",
       "96802                      0.0                      0.0   \n",
       "96803                      0.0                      0.0   \n",
       "96804                      0.0                      0.0   \n",
       "96805                      0.0                      0.0   \n",
       "\n",
       "       transaction_attribute_6  transaction_attribute_7  ...  \\\n",
       "0                          NaN                      NaN  ...   \n",
       "1                          0.0                      0.0  ...   \n",
       "2                          0.0                      0.0  ...   \n",
       "3                          0.0                      0.0  ...   \n",
       "4                          0.0                      0.0  ...   \n",
       "...                        ...                      ...  ...   \n",
       "96801                      0.0                      0.0  ...   \n",
       "96802                      0.0                      0.0  ...   \n",
       "96803                      0.0                      0.0  ...   \n",
       "96804                      0.0                      0.0  ...   \n",
       "96805                      0.0                      0.0  ...   \n",
       "\n",
       "       bureau_enquiry_47  bureau_enquiry_48  bureau_enquiry_49  \\\n",
       "0                    0.0                0.0                0.0   \n",
       "1                    0.0                0.0                2.0   \n",
       "2                    0.0                0.0                0.0   \n",
       "3                    0.0                0.0                0.0   \n",
       "4                    0.0                0.0                0.0   \n",
       "...                  ...                ...                ...   \n",
       "96801                0.0                0.0                0.0   \n",
       "96802                0.0                0.0                0.0   \n",
       "96803                0.0                0.0                0.0   \n",
       "96804                0.0                1.0                0.0   \n",
       "96805                0.0                0.0                0.0   \n",
       "\n",
       "       bureau_enquiry_50  onus_attribute_43  onus_attribute_44  \\\n",
       "0                    1.0                NaN                NaN   \n",
       "1                    3.0                0.0                0.0   \n",
       "2                    8.0                NaN                NaN   \n",
       "3                   30.0                NaN                NaN   \n",
       "4                    1.0                NaN                NaN   \n",
       "...                  ...                ...                ...   \n",
       "96801                1.0                NaN                NaN   \n",
       "96802                3.0                0.0                1.0   \n",
       "96803               20.0                NaN                NaN   \n",
       "96804                8.0                NaN                NaN   \n",
       "96805               25.0                NaN                NaN   \n",
       "\n",
       "       onus_attribute_45  onus_attribute_46  onus_attribute_47  \\\n",
       "0                    NaN                NaN                NaN   \n",
       "1                    0.0                0.0                0.0   \n",
       "2                    NaN                NaN                NaN   \n",
       "3                    NaN                NaN                NaN   \n",
       "4                    NaN                NaN                NaN   \n",
       "...                  ...                ...                ...   \n",
       "96801                NaN                NaN                NaN   \n",
       "96802                0.0                1.0                0.0   \n",
       "96803                NaN                NaN                NaN   \n",
       "96804                NaN                NaN                NaN   \n",
       "96805                NaN                NaN                NaN   \n",
       "\n",
       "       onus_attribute_48  \n",
       "0                    NaN  \n",
       "1                    0.0  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "...                  ...  \n",
       "96801                NaN  \n",
       "96802                0.0  \n",
       "96803                NaN  \n",
       "96804                NaN  \n",
       "96805                NaN  \n",
       "\n",
       "[96806 rows x 1216 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_number</th>\n",
       "      <th>bad_flag</th>\n",
       "      <th>onus_attribute_1</th>\n",
       "      <th>transaction_attribute_1</th>\n",
       "      <th>transaction_attribute_2</th>\n",
       "      <th>transaction_attribute_3</th>\n",
       "      <th>transaction_attribute_4</th>\n",
       "      <th>transaction_attribute_5</th>\n",
       "      <th>transaction_attribute_6</th>\n",
       "      <th>transaction_attribute_7</th>\n",
       "      <th>...</th>\n",
       "      <th>bureau_enquiry_47</th>\n",
       "      <th>bureau_enquiry_48</th>\n",
       "      <th>bureau_enquiry_49</th>\n",
       "      <th>bureau_enquiry_50</th>\n",
       "      <th>onus_attribute_43</th>\n",
       "      <th>onus_attribute_44</th>\n",
       "      <th>onus_attribute_45</th>\n",
       "      <th>onus_attribute_46</th>\n",
       "      <th>onus_attribute_47</th>\n",
       "      <th>onus_attribute_48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>221000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>86000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>215000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96801</th>\n",
       "      <td>96802</td>\n",
       "      <td>0</td>\n",
       "      <td>156000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96802</th>\n",
       "      <td>96803</td>\n",
       "      <td>0</td>\n",
       "      <td>46000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96803</th>\n",
       "      <td>96804</td>\n",
       "      <td>0</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96804</th>\n",
       "      <td>96805</td>\n",
       "      <td>0</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96805</th>\n",
       "      <td>96806</td>\n",
       "      <td>0</td>\n",
       "      <td>94000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96806 rows × 1216 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T11:11:32.341175Z",
     "start_time": "2025-01-11T11:11:26.723781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Explore the dataset\n",
    "print(\"Dataset Overview:\")\n",
    "print(data.head())\n",
    "print(\"\\nData Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Count the values of bad_flag\n",
    "print(\"\\nCount of bad_flag values:\")\n",
    "print(data['bad_flag'].value_counts())\n",
    "\n",
    "# Handle missing values\n",
    "data.fillna(data.median(numeric_only=True), inplace=True)\n",
    "data.fillna('Unknown', inplace=True)  # For categorical columns\n",
    "\n",
    "# Separate features and target variable (bad_flag)\n",
    "X = data.drop(columns=['bad_flag', 'account_number'])  # Exclude account_number\n",
    "y = data['bad_flag']\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "27d6f1c8388636d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "   account_number  bad_flag  onus_attribute_1  transaction_attribute_1  \\\n",
      "0               1         0          100000.0                      0.0   \n",
      "1               2         0          221000.0                      0.0   \n",
      "2               3         0           25000.0                      0.0   \n",
      "3               4         0           86000.0                      0.0   \n",
      "4               5         0          215000.0                      0.0   \n",
      "\n",
      "   transaction_attribute_2  transaction_attribute_3  transaction_attribute_4  \\\n",
      "0                      0.0                      0.0                      0.0   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   transaction_attribute_5  transaction_attribute_6  transaction_attribute_7  \\\n",
      "0                      0.0                      0.0                      0.0   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   ...  bureau_enquiry_47  bureau_enquiry_48  bureau_enquiry_49  \\\n",
      "0  ...                0.0                0.0                0.0   \n",
      "1  ...                0.0                0.0                2.0   \n",
      "2  ...                0.0                0.0                0.0   \n",
      "3  ...                0.0                0.0                0.0   \n",
      "4  ...                0.0                0.0                0.0   \n",
      "\n",
      "   bureau_enquiry_50  onus_attribute_43  onus_attribute_44  onus_attribute_45  \\\n",
      "0                1.0                0.0                1.0                0.0   \n",
      "1                3.0                0.0                0.0                0.0   \n",
      "2                8.0                0.0                1.0                0.0   \n",
      "3               30.0                0.0                1.0                0.0   \n",
      "4                1.0                0.0                1.0                0.0   \n",
      "\n",
      "   onus_attribute_46  onus_attribute_47  onus_attribute_48  \n",
      "0                1.0                0.0                0.0  \n",
      "1                0.0                0.0                0.0  \n",
      "2                1.0                0.0                0.0  \n",
      "3                1.0                0.0                0.0  \n",
      "4                1.0                0.0                0.0  \n",
      "\n",
      "[5 rows x 1216 columns]\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96806 entries, 0 to 96805\n",
      "Columns: 1216 entries, account_number to onus_attribute_48\n",
      "dtypes: float64(1189), int64(27)\n",
      "memory usage: 898.1 MB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "account_number             0\n",
      "bad_flag                   0\n",
      "onus_attribute_1           0\n",
      "transaction_attribute_1    0\n",
      "transaction_attribute_2    0\n",
      "                          ..\n",
      "onus_attribute_44          0\n",
      "onus_attribute_45          0\n",
      "onus_attribute_46          0\n",
      "onus_attribute_47          0\n",
      "onus_attribute_48          0\n",
      "Length: 1216, dtype: int64\n",
      "\n",
      "Count of bad_flag values:\n",
      "bad_flag\n",
      "0    95434\n",
      "1     1372\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tejas Tyagi\\AppData\\Local\\Temp\\ipykernel_22060\\2391818978.py:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data.fillna('Unknown', inplace=True)  # For categorical columns\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T11:19:30.842607Z",
     "start_time": "2025-01-11T11:11:36.516447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize and train the model with hyperparameter tuning\n",
    "model = GradientBoostingClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]"
   ],
   "id": "5ef35cca64958a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 10\u001B[0m\n\u001B[0;32m      3\u001B[0m param_grid \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_estimators\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m200\u001B[39m],\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlearning_rate\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m0.05\u001B[39m, \u001B[38;5;241m0.1\u001B[39m],\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m5\u001B[39m]\n\u001B[0;32m      7\u001B[0m }\n\u001B[0;32m      9\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mmodel, param_grid\u001B[38;5;241m=\u001B[39mparam_grid, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mroc_auc\u001B[39m\u001B[38;5;124m'\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 10\u001B[0m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# Best model from grid search\u001B[39;00m\n\u001B[0;32m     13\u001B[0m best_model \u001B[38;5;241m=\u001B[39m grid_search\u001B[38;5;241m.\u001B[39mbest_estimator_\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1150\u001B[0m     )\n\u001B[0;32m   1151\u001B[0m ):\n\u001B[1;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    892\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    893\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    894\u001B[0m     )\n\u001B[0;32m    896\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 898\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    900\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    901\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    902\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1421\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1422\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    837\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    838\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    839\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    840\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    841\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    842\u001B[0m         )\n\u001B[0;32m    843\u001B[0m     )\n\u001B[1;32m--> 845\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    846\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    847\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    848\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    849\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    850\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    851\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    852\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    853\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    854\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    855\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    856\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    857\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    858\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    859\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    860\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    863\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    864\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    865\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    866\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    867\u001B[0m     )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     60\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     61\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     62\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     64\u001B[0m )\n\u001B[1;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py:1863\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1861\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[0;32m   1862\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1863\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1865\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[0;32m   1866\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[0;32m   1867\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[0;32m   1868\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[0;32m   1869\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[0;32m   1870\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py:1792\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1790\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1791\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1792\u001B[0m res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1793\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1794\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    125\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:729\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    727\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    728\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 729\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    731\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    732\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[0;32m    733\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1150\u001B[0m     )\n\u001B[0;32m   1151\u001B[0m ):\n\u001B[1;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:532\u001B[0m, in \u001B[0;36mBaseGradientBoosting.fit\u001B[1;34m(self, X, y, sample_weight, monitor)\u001B[0m\n\u001B[0;32m    529\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_resize_state()\n\u001B[0;32m    531\u001B[0m \u001B[38;5;66;03m# fit the boosting stages\u001B[39;00m\n\u001B[1;32m--> 532\u001B[0m n_stages \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_stages\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    533\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    534\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    535\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraw_predictions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    536\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    537\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_rng\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    538\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    539\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    540\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    541\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbegin_at_stage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    542\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmonitor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    543\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    545\u001B[0m \u001B[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001B[39;00m\n\u001B[0;32m    546\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_stages \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:610\u001B[0m, in \u001B[0;36mBaseGradientBoosting._fit_stages\u001B[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001B[0m\n\u001B[0;32m    603\u001B[0m         initial_loss \u001B[38;5;241m=\u001B[39m loss_(\n\u001B[0;32m    604\u001B[0m             y[\u001B[38;5;241m~\u001B[39msample_mask],\n\u001B[0;32m    605\u001B[0m             raw_predictions[\u001B[38;5;241m~\u001B[39msample_mask],\n\u001B[0;32m    606\u001B[0m             sample_weight[\u001B[38;5;241m~\u001B[39msample_mask],\n\u001B[0;32m    607\u001B[0m         )\n\u001B[0;32m    609\u001B[0m \u001B[38;5;66;03m# fit next stage of trees\u001B[39;00m\n\u001B[1;32m--> 610\u001B[0m raw_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_stage\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    611\u001B[0m \u001B[43m    \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    612\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    613\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    614\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraw_predictions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    615\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    616\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    617\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    618\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_csc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    619\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_csr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    620\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    622\u001B[0m \u001B[38;5;66;03m# track loss\u001B[39;00m\n\u001B[0;32m    623\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m do_oob:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:245\u001B[0m, in \u001B[0;36mBaseGradientBoosting._fit_stage\u001B[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001B[0m\n\u001B[0;32m    242\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m sample_weight \u001B[38;5;241m*\u001B[39m sample_mask\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[0;32m    244\u001B[0m X \u001B[38;5;241m=\u001B[39m X_csr \u001B[38;5;28;01mif\u001B[39;00m X_csr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m X\n\u001B[1;32m--> 245\u001B[0m \u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresidual\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    247\u001B[0m \u001B[38;5;66;03m# update tree leaves\u001B[39;00m\n\u001B[0;32m    248\u001B[0m loss\u001B[38;5;241m.\u001B[39mupdate_terminal_regions(\n\u001B[0;32m    249\u001B[0m     tree\u001B[38;5;241m.\u001B[39mtree_,\n\u001B[0;32m    250\u001B[0m     X,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    257\u001B[0m     k\u001B[38;5;241m=\u001B[39mk,\n\u001B[0;32m    258\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1150\u001B[0m     )\n\u001B[0;32m   1151\u001B[0m ):\n\u001B[1;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001B[0m, in \u001B[0;36mDecisionTreeRegressor.fit\u001B[1;34m(self, X, y, sample_weight, check_input)\u001B[0m\n\u001B[0;32m   1290\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   1291\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m   1292\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001B[39;00m\n\u001B[0;32m   1293\u001B[0m \n\u001B[0;32m   1294\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1317\u001B[0m \u001B[38;5;124;03m        Fitted estimator.\u001B[39;00m\n\u001B[0;32m   1318\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1320\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1321\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1322\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1323\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1324\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1325\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001B[0m, in \u001B[0;36mBaseDecisionTree._fit\u001B[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001B[0m\n\u001B[0;32m    432\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    433\u001B[0m     builder \u001B[38;5;241m=\u001B[39m BestFirstTreeBuilder(\n\u001B[0;32m    434\u001B[0m         splitter,\n\u001B[0;32m    435\u001B[0m         min_samples_split,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    440\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_impurity_decrease,\n\u001B[0;32m    441\u001B[0m     )\n\u001B[1;32m--> 443\u001B[0m \u001B[43mbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    445\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m is_classifier(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    446\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate the model\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"\\nROC AUC Score:\", roc_auc)\n",
    "\n",
    "# Load validation data\n",
    "validation_path = 'validation_data_to_be_shared.csv'  # Replace with your file path\n",
    "validation_data = pd.read_csv(validation_path)\n",
    "\n",
    "# Preprocess validation data\n",
    "validation_data.fillna(data.median(numeric_only=True), inplace=True)\n",
    "X_validation = validation_data.drop(columns=['account_number'])\n",
    "X_validation = pd.get_dummies(X_validation, drop_first=True)\n",
    "\n",
    "# Align columns with training data\n",
    "X_validation = X_validation.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Predict probabilities for validation data\n",
    "validation_data['predicted_probability'] = best_model.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "# Save predictions\n",
    "validation_data[['account_number', 'predicted_probability']].to_csv('validation_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions for validation data saved to 'validation_predictions.csv'.\")"
   ],
   "id": "1957486a7cb4c9cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T11:26:25.574385Z",
     "start_time": "2025-01-11T11:26:11.092988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import parallel_backend\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the development dataset\n",
    "data_path = 'Dev_data_to_be_shared.csv'  # Replace with your file path\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Explore the dataset\n",
    "print(\"Dataset Overview:\")\n",
    "print(data.head())\n",
    "print(\"\\nData Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Count the values of bad_flag\n",
    "print(\"\\nCount of bad_flag values:\")\n",
    "print(data['bad_flag'].value_counts())\n",
    "\n",
    "# Handle missing values\n",
    "data.fillna(data.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Separate features and target variable (bad_flag)\n",
    "X = data.drop(columns=['bad_flag', 'account_number'])  # Exclude account_number\n",
    "y = data['bad_flag']\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the model with hyperparameter tuning\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "cafbbda0c1b5ec9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "   account_number  bad_flag  onus_attribute_1  transaction_attribute_1  \\\n",
      "0               1         0               NaN                      NaN   \n",
      "1               2         0          221000.0                      0.0   \n",
      "2               3         0           25000.0                      0.0   \n",
      "3               4         0           86000.0                      0.0   \n",
      "4               5         0          215000.0                      0.0   \n",
      "\n",
      "   transaction_attribute_2  transaction_attribute_3  transaction_attribute_4  \\\n",
      "0                      NaN                      NaN                      NaN   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   transaction_attribute_5  transaction_attribute_6  transaction_attribute_7  \\\n",
      "0                      NaN                      NaN                      NaN   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   ...  bureau_enquiry_47  bureau_enquiry_48  bureau_enquiry_49  \\\n",
      "0  ...                0.0                0.0                0.0   \n",
      "1  ...                0.0                0.0                2.0   \n",
      "2  ...                0.0                0.0                0.0   \n",
      "3  ...                0.0                0.0                0.0   \n",
      "4  ...                0.0                0.0                0.0   \n",
      "\n",
      "   bureau_enquiry_50  onus_attribute_43  onus_attribute_44  onus_attribute_45  \\\n",
      "0                1.0                NaN                NaN                NaN   \n",
      "1                3.0                0.0                0.0                0.0   \n",
      "2                8.0                NaN                NaN                NaN   \n",
      "3               30.0                NaN                NaN                NaN   \n",
      "4                1.0                NaN                NaN                NaN   \n",
      "\n",
      "   onus_attribute_46  onus_attribute_47  onus_attribute_48  \n",
      "0                NaN                NaN                NaN  \n",
      "1                0.0                0.0                0.0  \n",
      "2                NaN                NaN                NaN  \n",
      "3                NaN                NaN                NaN  \n",
      "4                NaN                NaN                NaN  \n",
      "\n",
      "[5 rows x 1216 columns]\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96806 entries, 0 to 96805\n",
      "Columns: 1216 entries, account_number to onus_attribute_48\n",
      "dtypes: float64(1189), int64(27)\n",
      "memory usage: 898.1 MB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "account_number                 0\n",
      "bad_flag                       0\n",
      "onus_attribute_1           25231\n",
      "transaction_attribute_1    25231\n",
      "transaction_attribute_2    25231\n",
      "                           ...  \n",
      "onus_attribute_44          85196\n",
      "onus_attribute_45          85196\n",
      "onus_attribute_46          85196\n",
      "onus_attribute_47          85196\n",
      "onus_attribute_48          85196\n",
      "Length: 1216, dtype: int64\n",
      "\n",
      "Count of bad_flag values:\n",
      "bad_flag\n",
      "0    95434\n",
      "1     1372\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T11:28:36.004838Z",
     "start_time": "2025-01-11T11:26:26.981034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = GradientBoostingClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "def print_progress(cv_results):\n",
    "    print(\"\\nProgress Report:\")\n",
    "    for i in range(len(cv_results['params'])):\n",
    "        print(f\"Parameters: {cv_results['params'][i]} - Mean ROC AUC: {cv_results['mean_test_score'][i]:.4f}\")\n",
    "\n",
    "with parallel_backend('threading'):\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=1, return_train_score=True)\n",
    "    print(\"Starting Grid Search...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print_progress(grid_search.cv_results_)\n",
    "\n",
    "# Best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"\\nBest Parameters:\", grid_search.best_params_)\n",
    "print(\"Best ROC AUC Score:\", grid_search.best_score_)"
   ],
   "id": "34477f54cbc66aa0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"\\nROC AUC Score:\", roc_auc)\n",
    "\n",
    "# Load validation data\n",
    "validation_path = 'validation_data_to_be_shared.csv'  # Replace with your file path\n",
    "validation_data = pd.read_csv(validation_path)\n",
    "\n",
    "# Preprocess validation data\n",
    "validation_data.fillna(data.median(numeric_only=True), inplace=True)\n",
    "X_validation = validation_data.drop(columns=['account_number'])\n",
    "X_validation = pd.get_dummies(X_validation, drop_first=True)\n",
    "\n",
    "# Align columns with training data\n",
    "X_validation = X_validation.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Predict probabilities for validation data\n",
    "validation_data['predicted_probability'] = best_model.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "# Save predictions\n",
    "validation_data[['account_number', 'predicted_probability']].to_csv('validation_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions for validation data saved to 'validation_predictions.csv'.\")"
   ],
   "id": "b15ef2c548d80c69"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
