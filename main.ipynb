{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T10:40:52.682341Z",
     "start_time": "2025-01-11T10:40:44.407704Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data_path = 'Dev_data_to_be_shared.csv'  # Replace with your file path\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Explore the dataset\n",
    "# print(\"Dataset Overview:\")\n",
    "# print(data.head())\n",
    "# print(\"\\nData Info:\")\n",
    "# print(data.info())\n",
    "# print(\"\\nMissing Values:\")\n",
    "# print(data.isnull().sum())\n",
    "# \n",
    "# # Handle missing values (if any)\n",
    "# data.fillna(data.median(numeric_only=True), inplace=True)\n",
    "# \n",
    "# # Separate features and target variable (bad_flag)\n",
    "# X = data.drop(columns=['bad_flag'])\n",
    "# y = data['bad_flag']\n",
    "# \n",
    "# # Convert categorical variables into dummy/indicator variables (if applicable)\n",
    "# X = pd.get_dummies(X, drop_first=True)\n",
    "# \n",
    "# # Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# \n",
    "# # Initialize the model\n",
    "# model = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)\n",
    "# \n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train)\n",
    "# \n",
    "# # Make predictions\n",
    "# y_pred = model.predict(X_test)\n",
    "# \n",
    "# # Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"\\nAccuracy:\", accuracy)\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# \n",
    "# # Feature Importance (Optional)\n",
    "# feature_importance = pd.DataFrame({\n",
    "#     'Feature': X.columns,\n",
    "#     'Importance': model.feature_importances_\n",
    "# }).sort_values(by='Importance', ascending=False)\n",
    "# \n",
    "# print(\"\\nFeature Importances:\")\n",
    "# print(feature_importance)\n",
    "# \n",
    "# # Save the trained model (Optional)\n",
    "# import joblib\n",
    "# joblib.dump(model, 'bad_flag_model.pkl')\n",
    "# \n",
    "# print(\"Model training and evaluation complete.\")\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:40:57.812195Z",
     "start_time": "2025-01-11T10:40:57.551603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Dataset Overview:\")\n",
    "print(data.head())\n",
    "print(\"\\nData Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())"
   ],
   "id": "3ec121e8e1740af3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "   account_number  bad_flag  onus_attribute_1  transaction_attribute_1  \\\n",
      "0               1         0               NaN                      NaN   \n",
      "1               2         0          221000.0                      0.0   \n",
      "2               3         0           25000.0                      0.0   \n",
      "3               4         0           86000.0                      0.0   \n",
      "4               5         0          215000.0                      0.0   \n",
      "\n",
      "   transaction_attribute_2  transaction_attribute_3  transaction_attribute_4  \\\n",
      "0                      NaN                      NaN                      NaN   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   transaction_attribute_5  transaction_attribute_6  transaction_attribute_7  \\\n",
      "0                      NaN                      NaN                      NaN   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                      0.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   ...  bureau_enquiry_47  bureau_enquiry_48  bureau_enquiry_49  \\\n",
      "0  ...                0.0                0.0                0.0   \n",
      "1  ...                0.0                0.0                2.0   \n",
      "2  ...                0.0                0.0                0.0   \n",
      "3  ...                0.0                0.0                0.0   \n",
      "4  ...                0.0                0.0                0.0   \n",
      "\n",
      "   bureau_enquiry_50  onus_attribute_43  onus_attribute_44  onus_attribute_45  \\\n",
      "0                1.0                NaN                NaN                NaN   \n",
      "1                3.0                0.0                0.0                0.0   \n",
      "2                8.0                NaN                NaN                NaN   \n",
      "3               30.0                NaN                NaN                NaN   \n",
      "4                1.0                NaN                NaN                NaN   \n",
      "\n",
      "   onus_attribute_46  onus_attribute_47  onus_attribute_48  \n",
      "0                NaN                NaN                NaN  \n",
      "1                0.0                0.0                0.0  \n",
      "2                NaN                NaN                NaN  \n",
      "3                NaN                NaN                NaN  \n",
      "4                NaN                NaN                NaN  \n",
      "\n",
      "[5 rows x 1216 columns]\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96806 entries, 0 to 96805\n",
      "Columns: 1216 entries, account_number to onus_attribute_48\n",
      "dtypes: float64(1189), int64(27)\n",
      "memory usage: 898.1 MB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "account_number                 0\n",
      "bad_flag                       0\n",
      "onus_attribute_1           25231\n",
      "transaction_attribute_1    25231\n",
      "transaction_attribute_2    25231\n",
      "                           ...  \n",
      "onus_attribute_44          85196\n",
      "onus_attribute_45          85196\n",
      "onus_attribute_46          85196\n",
      "onus_attribute_47          85196\n",
      "onus_attribute_48          85196\n",
      "Length: 1216, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c1a75c4b3d2a52bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:43:27.945348Z",
     "start_time": "2025-01-11T10:43:27.509430Z"
    }
   },
   "cell_type": "code",
   "source": "print(data.isnull().sum())\n",
   "id": "b3d9bb4cff42c3a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account_number             0\n",
      "bad_flag                   0\n",
      "onus_attribute_1           0\n",
      "transaction_attribute_1    0\n",
      "transaction_attribute_2    0\n",
      "                          ..\n",
      "onus_attribute_44          0\n",
      "onus_attribute_45          0\n",
      "onus_attribute_46          0\n",
      "onus_attribute_47          0\n",
      "onus_attribute_48          0\n",
      "Length: 1216, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:46:24.404717Z",
     "start_time": "2025-01-11T10:46:19.226911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data.fillna(data.median(numeric_only=True), inplace=True)\n",
    "data.fillna('Unknown', inplace=True)  # For categorical columns\n",
    "# Separate features and target variable (bad_flag)\n",
    "X = data.drop(columns=['bad_flag'])\n",
    "y = data['bad_flag']\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables (if applicable)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ],
   "id": "6ad0134f1ebd9c37",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:46:59.238349Z",
     "start_time": "2025-01-11T10:46:24.414038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the model\n",
    "model = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "83e9f2ccaf50ef47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.98578600499969\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     47715\n",
      "           1       0.00      0.00      0.00       688\n",
      "\n",
      "    accuracy                           0.99     48403\n",
      "   macro avg       0.49      0.50      0.50     48403\n",
      "weighted avg       0.97      0.99      0.98     48403\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tejas Tyagi\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tejas Tyagi\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tejas Tyagi\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T10:45:53.247250Z",
     "start_time": "2025-01-11T10:45:53.161007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature Importance (Optional)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Save the trained model (Optional)\n",
    "import joblib\n",
    "joblib.dump(model, 'bad_flag_model.pkl')\n",
    "\n",
    "print(\"Model training and evaluation complete.\")\n"
   ],
   "id": "9c08d0a2360a7e73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importances:\n",
      "                        Feature  Importance\n",
      "1116           onus_attribute_2    0.012664\n",
      "1134          onus_attribute_20    0.009366\n",
      "1131          onus_attribute_17    0.009190\n",
      "810                  bureau_145    0.007738\n",
      "1103                 bureau_439    0.007274\n",
      "...                         ...         ...\n",
      "198   transaction_attribute_197    0.000000\n",
      "344   transaction_attribute_343    0.000000\n",
      "197   transaction_attribute_196    0.000000\n",
      "240   transaction_attribute_239    0.000000\n",
      "314   transaction_attribute_313    0.000000\n",
      "\n",
      "[1213 rows x 2 columns]\n",
      "Model training and evaluation complete.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ead44ef95c36f33e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "27d6f1c8388636d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
